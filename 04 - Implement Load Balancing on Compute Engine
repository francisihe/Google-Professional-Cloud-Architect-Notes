LAB 1: Creating a Virtual Machine

You can create virtual machines using 
a. The Cloud Shell, from the Cloud console
b. Using the gcloud command

a. Using the Cloud Shell:
In Cloud Shell, you click on Compute Engine - VM Instances, click 'Create Instance', fill in the parameters and hit create. You can SSH into it as well.

You then install the NGINX web server
1. Update the OS using 'sudo apt-get update'
2. Install NGINX using 'sudo apt-get install -y nginx'
3. Confirm that NGINX is running using 'ps auwx | grep nginx'
4. Click on the external IP to see the default page in a new browser

b. Using gclound command

1. You use the command:
gcloud compute instances create $NAME --machine-type e2-medium --zone=$ZONE
Sample output:

     Created [...gcelab2].
     NAME: gcelab2
     ZONE:  Zone
     MACHINE_TYPE: e2-medium
     PREEMPTIBLE:
     INTERNAL_IP: 10.128.0.3
     EXTERNAL_IP: 34.136.51.150
     STATUS: RUNNING

2. To see the defaults run: 'gcloud compute instances create --help'

===================

LAB 2: Getting Started with Cloud Shell and gcloud

1. Command to set the region: 'gcloud config set compute/region REGION'
2. Command to view the region setting: 'gcloud config get-value compute/region'
3. Command to set the zone: 'gcloud config set compute/zone ZONE'
4. Command to view project zone setting: 'gcloud config get-value compute/zone'
5. Command to view project id: 'gcloud config get-value project'
6. Command to view details of the project in 5 above: 'gcloud compute project-info describe --project $(gcloud config get-value project)'
7. Setting env variable to store project ID: export PROJECT_ID=$(gcloud config get-value project)
8. Setting env variable to store Zone: export ZONE=$(gcloud config get-value compute/zone)
9. View the set variables: echo -e "PROJECT ID: $PROJECT_ID\nZONE: $ZONE"

++ Creating the VM machine: 'gcloud compute instances create gcelab2 --machine-type e2-medium --zone $ZONE'

Other gcloud commands:
1. For help: 'gcloud -h' or 'gcloud config --help' or 'gcloud help config'
2. View the list of configurations: 'gcloud config list'
3. See all properties and their settings: 'gcloud config list --all'
4. List all components: 'gcloud components list'

++ Filtering command-line output
1. List the compute instance available in the project: 'gcloud compute instances list'
2. List the gcelab2 VM that I created prior: gcloud compute instances list --filter="name=('gcelab2')"
3. List the firewall rules in the project: gcloud compute firewall-rules list
4. List the firewall rules for the default network: gcloud compute firewall-rules list --filter="network='default'"
5. List the firewall rules for the default network where the allow rule matches an ICMP rule: gcloud compute firewall-rules list --filter="NETWORK:'default' AND ALLOW:'icmp'"

++ Connecting to your VM instance
1. To connect to your VM with SSH, run the following command: gcloud compute ssh gcelab2 --zone $ZONE
2. You can leave the passphrases empty. When the prompt now says something similar to sa_107021519685252337470@gcelab2, it confirms you have SSH'd into it. The reference before the @ indicates the account being used.
After the @ sign indicates the host machine being accessed.
3. You can then install the nginx web server: sudo apt install -y nginx
4. To quit: exit

++ Updating the firewall
1. List the firewall rules for the project: gcloud compute firewall-rules list
2. Try to access the nginx service running on the gcelab2 virtual machine.

Note: Communication with the virtual machine will fail as it does not have an appropriate firewall rule. The nginx web server is expecting to communicate on tcp:80. To get communication working you need to:

Add a tag to the gcelab2 virtual machine
Add a firewall rule for http traffic

3. Add a tag to the virtual machine: gcloud compute instances add-tags gcelab2 --tags http-server,https-server
4. Update the firewall rule to allow traffic: gcloud compute firewall-rules create default-allow-http --direction=INGRESS --priority=1000 --network=default --action=ALLOW --rules=tcp:80 --source-ranges=0.0.0.0/0 --target-tags=http-server
5. List the firewall rules for the project: gcloud compute firewall-rules list --filter=ALLOW:'80'
6. Verify communication is possible for http to the virtual machine: curl http://$(gcloud compute instances list --filter=name:gcelab2 --format='value(EXTERNAL_IP)')


++ Viewing the system logs
1. View the available logs on the system: gcloud logging logs list
2. View the logs that relate to compute resources: gcloud logging logs list --filter="compute"
3. Read the logs related to the resource type of gce_instance: gcloud logging read "resource.type=gce_instance" --limit 5
4. Read the logs for a specific virtual machine: gcloud logging read "resource.type=gce_instance AND labels.instance_name='gcelab2'" --limit 5


===============================


LAB 3: Set Up Network and HTTP Load Balancers

Load balancers only work when the VMs, instance groups or network endpoints are in the same region and project.

There are two types of load balancers:
1. Network Load Balancer (https://cloud.google.com/load-balancing/docs/network/networklb-backend-service)
2. HTTP(s) Load Balancer (https://cloud.google.com/load-balancing/docs/https)

++  Set the default region and zone for all resources
1. Set the default region: gcloud config set compute/region $Region
2. Set the default zone: gcloud config set compute/zone $Zone


++  Create multiple web server instances


Personal Note: In doing this, we create the different instances, 2 or more, give them the same tag for easy identification and filtering. An example command is below. 

In this command, we create the instance with the name 'www1', and other flags. The metadata flag has a script, and a brief explanation of that script is below the command:

  gcloud compute instances create www1 \
    --zone=Zone \
    --tags=network-lb-tag \
    --machine-type=e2-small \
    --image-family=debian-11 \
    --image-project=debian-cloud \
    --metadata=startup-script='#!/bin/bash
      apt-get update
      apt-get install apache2 -y
      service apache2 restart
      echo "
<h3>Web Server: www1</h3>" | tee /var/www/html/index.html'

Brief explanation of script:
1. --metadata=startup-script specifies the name of the script
2. #!/bin/bash shows that it is a bash script with several commands within it
3. These apt-get update && apt-get install apache2 -y get updates and install apache. -y allows it run with yes in response to any questions, so it installs without requiring manual intervention
4. service apache2 restart is to restart the apache service
5. echo "<h3>Web Server: www1</h3>" is basically to return the item in the quote
6. tee /var/www/html/index.html' is a command to create an index.html file at that location, to display the message above

1. We run the command above, changing the name using www1, www2, www3 as desired
2. We then create a firewall rule to allow external traffic to the VM instances: gcloud compute firewall-rules create www-firewall-network-lb \
    --target-tags network-lb-tag --allow tcp:80
3. To see the instances created: gcloud compute instances list
4. We can 'curl http://[IP_ADDRESS]' the external IP addresses of each instance to verify that they work


++ Configure the load balancing service
Read more: https://cloud.google.com/compute/docs/load-balancing/network/

Personal Note: To get the load balancing service to work, we need to create and expose a public-facing IP address, create a target pool and add a health check, add those instances created to the pool, as the pool now basically works as one source. Then we add a forwarding rule that exposes the IP and directs the traffic to the pool of compute instances. 

1. Create a static external IP address for your load balancer: gcloud compute addresses create network-lb-ip-1 \
  --region Region
2. Add a legacy HTTP health check resource: gcloud compute http-health-checks create basic-check
3. Add a target pool in the same region as your instances. Run the following to create the target pool and use the health check, which is required for the service to function: gcloud compute target-pools create www-pool \
  --region Region --http-health-check basic-check
4. Add the instances to the pool: gcloud compute target-pools add-instances www-pool \
    --instances www1,www2,www3
5. Add a forwarding rule: gcloud compute forwarding-rules create www-rule \
    --region  Region \
    --ports 80 \
    --address network-lb-ip-1 \
    --target-pool www-pool


++ Sending traffic to your instances

Personal note: After configuring the load balancer, we can then get the external IP of the forwarding rule, which is used by the load balancer to direct traffic to the VMS in the pool.
1. To view the external IP of the forwarding rule: gcloud compute forwarding-rules describe www-rule --region Region
2. Access the external IP address and assign it to a variable: IPADDRESS=$(gcloud compute forwarding-rules describe www-rule --region Region --format="json" | jq -r .IPAddress)
3. Show the external IP address: echo $IPADDRESS
4. We can then see the working process by testing with a curl to the addresses: while true; do curl -m1 $IPADDRESS; done


++ Create an HTTP load balancer

HTTP(S) Load Balancing is implemented on Google Front End (GFE). GFEs are distributed globally and operate together using Google's global network and control plane. You can configure URL rules to route some URLs to one set of instances and route other URLs to other instances.

Requests are always routed to the instance group that is closest to the user, if that group has enough capacity and is appropriate for the request. If the closest group does not have enough capacity, the request is sent to the closest group that does have capacity.

To set up a load balancer with a Compute Engine backend, your VMs need to be in an instance group. The managed instance group provides VMs running the backend servers of an external HTTP load balancer. For this lab, backends serve their own hostnames.

First, create the load balancer template:

gcloud compute instance-templates create lb-backend-template \
   --region=Region \
   --network=default \
   --subnet=default \
   --tags=allow-health-check \
   --machine-type=e2-medium \
   --image-family=debian-11 \
   --image-project=debian-cloud \
   --metadata=startup-script='#!/bin/bash
     apt-get update
     apt-get install apache2 -y
     a2ensite default-ssl
     a2enmod ssl
     vm_hostname="$(curl -H "Metadata-Flavor:Google" \
     http://169.254.169.254/computeMetadata/v1/instance/name)"
     echo "Page served from: $vm_hostname" | \
     tee /var/www/html/index.html
     systemctl restart apache2'

Managed instance groups (MIGs) let you operate apps on multiple identical VMs. You can make your workloads scalable and highly available by taking advantage of automated MIG services, including: autoscaling, autohealing, regional (multiple zone) deployment, and automatic updating.

Create a managed instance group based on the template:

gcloud compute instance-groups managed create lb-backend-group \
   --template=lb-backend-template --size=2 --zone=Zone

Create the fw-allow-health-check firewall rule.

gcloud compute firewall-rules create fw-allow-health-check \
  --network=default \
  --action=allow \
  --direction=ingress \
  --source-ranges=130.211.0.0/22,35.191.0.0/16 \
  --target-tags=allow-health-check \
  --rules=tcp:80

Note: The ingress rule allows traffic from the Google Cloud health checking systems (130.211.0.0/22 and 35.191.0.0/16). This lab uses the target tag allow-health-check to identify the VMs
Now that the instances are up and running, set up a global static external IP address that your customers use to reach your load balancer:

gcloud compute addresses create lb-ipv4-1 \
  --ip-version=IPV4 \
  --global

Note the IPv4 address that was reserved:

gcloud compute addresses describe lb-ipv4-1 \
  --format="get(address)" \
  --global

Create a health check for the load balancer:

gcloud compute health-checks create http http-basic-check \
  --port 80

Note: Google Cloud provides health checking mechanisms that determine whether backend instances respond properly to traffic. For more information, please refer to the Creating health checks document.
Create a backend service:

gcloud compute backend-services create web-backend-service \
  --protocol=HTTP \
  --port-name=http \
  --health-checks=http-basic-check \
  --global

Add your instance group as the backend to the backend service:

gcloud compute backend-services add-backend web-backend-service \
  --instance-group=lb-backend-group \
  --instance-group-zone=Zone \
  --global

Create a URL map to route the incoming requests to the default backend service:

gcloud compute url-maps create web-map-http \
    --default-service web-backend-service

Note: URL map is a Google Cloud configuration resource used to route requests to backend services or backend buckets. For example, with an external HTTP(S) load balancer, you can use a single URL map to route requests to different destinations based on the rules configured in the URL map:
Requests for https://example.com/video go to one backend service.
Requests for https://example.com/audio go to a different backend service.
Requests for https://example.com/images go to a Cloud Storage backend bucket.
Requests for any other host and path combination go to a default backend service.
Create a target HTTP proxy to route requests to your URL map:

gcloud compute target-http-proxies create http-lb-proxy \
    --url-map web-map-http

Create a global forwarding rule to route incoming requests to the proxy:

gcloud compute forwarding-rules create http-content-rule \
   --address=lb-ipv4-1\
   --global \
   --target-http-proxy=http-lb-proxy \
   --ports=80

===================

NOTE ON NETWORK LOAD BALANCER VS HTTP LOAD BALANCER

Creating a Network Load Balancer (NLB) and an HTTP(S) Load Balancer serves different purposes due to the layers of the OSI model they operate on and the specific use cases they address.

### Key Differences

1. **Layer of Operation:**
   - **Network Load Balancer:** Operates at Layer 4 (Transport Layer) of the OSI model. It routes traffic based on IP addresses and TCP/UDP port numbers. Itâ€™s ideal for handling raw traffic and is more suitable for non-HTTP protocols.
   - **HTTP(S) Load Balancer:** Operates at Layer 7 (Application Layer). It understands HTTP(S) requests, allowing it to make routing decisions based on the content of the requests, such as URL paths or headers.

2. **Features:**
   - **Network Load Balancer:**
     - Simple and low-latency routing.
     - Supports both TCP and UDP traffic.
     - Generally used for applications that do not need advanced routing capabilities.

   - **HTTP(S) Load Balancer:**
     - Advanced features like URL mapping, SSL termination, and content-based routing.
     - Supports features like caching, GZIP compression, and WebSocket connections.
     - Ideal for web applications where routing decisions need to be based on the request content.

3. **Use Cases:**
   - **NLB Use Cases:** Suitable for applications needing high throughput and low latency, like gaming servers, VoIP, or any non-HTTP service.
   - **HTTP(S) Load Balancer Use Cases:** Best for serving web applications where you want to direct traffic based on URL, serve different content based on the request, or handle SSL certificates.

### When to Use Both

In some architectures, you might want to use both load balancers:
- The **NLB** can handle high-speed TCP traffic to your backend services, while the **HTTP(S) Load Balancer** can route HTTP traffic to different services based on URL patterns, ensuring optimized content delivery and application performance.

### Summary

In essence, you create a Network Load Balancer for general TCP/UDP traffic management and an HTTP(S) Load Balancer for more advanced web application traffic management. Each serves its unique role, providing flexibility and efficiency based on your specific application needs.
